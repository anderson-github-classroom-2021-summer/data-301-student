---
jupyter:
  jupytext:
    formats: ipynb,md
    text_representation:
      extension: .md
      format_name: markdown
      format_version: '1.2'
      jupytext_version: 1.8.0
  kernelspec:
    display_name: Python 3
    language: python
    name: python3
---

# Chapter 1.

## Data Science as a Field

What does data science look like today? Well. It depends on who you ask. Industry or academics. Statistics folks or computer science folks. Small company or large company. Tech company or company using tech. It really depends on who you ask which is the case for most fields, but this is especially true in data science.

So how do we teach data science? It's important to start with the type of data scientist we want to train and at what level of expertise. For the sake of discussion, consider the following three levels. The first level is data science literacy and understanding. This type of data scientist isn't really a data scientist at all, but they know something about the field that can help them in their lives. The second level of data scientist is often a domain expert with a basic understanding of the field in general and a deep understanding in their domain and possibly one area of data science (e.g., neural networks). The third type of data science has a broad and deep understanding of the field. This book is aimed at the second and third type of data scientist. 


### Data Science Technology

Data science technology evolves rapidly. One way to view technology is through the lense of how a data scientist spends their time.
<img src="datasciencetime.jpg">


### Data cleaning and Organization

As you can see from above, a lot of time is spent on cleaning and organizing data. What tools and technology are used for data cleaning and organization?
* Pipelines
* Databases

Pipelines can be as simple as a data scientist has custom scripts or commands to clean data in a standard way for their purposes, or as sophisticated as a generic platform from Google that attempts to automate data cleaning and processing.


### Collecting data sets
This is the second most time consuming process and often times it is one that you have to revisit multiple times (the same holds true in general, which is why pipelining is so important). You don't just need a lot of data. You need the right kind of data. Sometimes this is "impossible" given other constraints and there is nothing the best data scientist in the world could accomplish.


### Mining data for patterns
This is what we all think about when we envision our day. It is amazing when you can make some clever choices and nail that result or visualization. But the truth of the matter is a lot of this can and is automated. What isn't automated and won't be any time soon are details about algorithmic fairness, algorithmic bias, strengths and weaknesses, intuition, etc. But auto machine learning is here to say, and it is believed by many to be the future.

```python

```
